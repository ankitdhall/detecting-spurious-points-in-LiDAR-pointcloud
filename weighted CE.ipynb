{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  1 100 100   1 100]\n",
      "  [  1 100 100   1 100]\n",
      "  [  1 100   1 100   1]\n",
      "  [  1   1 100   1   1]\n",
      "  [  1   1 100   1   1]]\n",
      "\n",
      " [[100   1 100   1   1]\n",
      "  [  1 100 100 100   1]\n",
      "  [100 100 100 100   1]\n",
      "  [  1 100   1   1   1]\n",
      "  [100   1 100 100 100]]\n",
      "\n",
      " [[100   1   1   1 100]\n",
      "  [  1 100 100   1 100]\n",
      "  [100 100 100 100   1]\n",
      "  [100 100 100   1 100]\n",
      "  [100   1 100 100 100]]\n",
      "\n",
      " [[  1   1   1   1   1]\n",
      "  [100 100   1 100   1]\n",
      "  [  1 100 100   1   1]\n",
      "  [100   1   1   1 100]\n",
      "  [100 100   1 100   1]]]\n",
      "output:\n",
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  0.0373  0.3893 -0.3046 -0.5425 -0.0286\n",
      "  0.1534 -0.3853 -0.6698  0.6767 -1.3138\n",
      " -0.9943  0.4125  0.8173  0.8385  1.0269\n",
      "  0.6848 -1.3208 -2.4506 -0.8145  1.5627\n",
      " -0.0042  0.0128 -0.6823 -1.6604 -0.0777\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      " -0.6421  2.0751 -0.0685  0.6070 -0.2398\n",
      "  0.9490  2.0042 -0.9256 -0.1204 -1.0529\n",
      " -0.7213 -1.9756 -1.4168 -1.8621 -0.1894\n",
      " -0.6009 -2.0994  1.1383 -0.0519  0.5678\n",
      " -3.3109  2.1844 -2.6233 -2.7534  0.0162\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -1.0066  0.2804  0.9614 -1.3237 -0.3183\n",
      " -1.0865  0.0767 -1.8128 -0.5526  0.7723\n",
      "  0.5181 -0.1463  0.4887 -0.6509  3.0063\n",
      " -0.3556  1.0463  1.0026 -0.9119  1.5023\n",
      " -0.4427 -0.2962  0.7744 -2.3796  0.5382\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      " -0.5419  1.1129 -0.6423 -0.8097  0.8438\n",
      " -0.1119 -0.9995  0.0867 -1.7759  0.8402\n",
      "  0.3700 -0.1073 -1.8628 -0.0048 -0.0281\n",
      " -1.8364  0.0898 -0.7235 -0.6945 -0.3366\n",
      "  1.1091 -1.5013  0.9967  1.7949  0.5036\n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -1.8373  0.2899  0.1714  0.2344  2.4975\n",
      " -0.0651  0.1794  1.3898  0.6154 -0.2609\n",
      " -0.1889  0.3222 -0.6767  0.6324  0.5272\n",
      "  0.4976 -0.2876  1.6317  0.3041 -0.7123\n",
      " -1.9425 -0.7505  0.0857 -0.2545  0.7022\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      " -0.3343 -0.1754 -0.8406 -0.6174  1.9551\n",
      " -1.6890 -0.4770  0.0904  0.0467  0.0527\n",
      "  0.8160  1.3645  1.0292  0.9100  0.1478\n",
      " -0.8208  1.6280 -0.8328 -0.7049  0.2186\n",
      " -0.1081  1.9190  1.0988  0.4557 -0.1387\n",
      "\n",
      "(3 ,0 ,.,.) = \n",
      "  0.5223 -0.1722  0.0286 -1.5558  1.1846\n",
      "  0.3767 -0.2084 -0.6620 -1.4556 -0.0227\n",
      " -0.9324 -0.7321  0.1383  0.1543 -0.0186\n",
      " -1.4447 -0.1575  1.6632 -0.1721  0.2027\n",
      " -1.3852  0.9365  0.2373  1.3387 -1.2916\n",
      "\n",
      "(3 ,1 ,.,.) = \n",
      "  1.4127 -2.4286 -1.4495 -0.1662  0.5743\n",
      "  0.5409  1.1111 -0.2969  0.3925  0.3779\n",
      "  1.8936  0.3545 -0.1783  0.0703 -2.2590\n",
      " -0.8932  1.0643  0.3256  0.0991 -2.0989\n",
      "  0.1168  0.0242  0.0108 -1.7338  0.1459\n",
      "[torch.FloatTensor of size 4x2x5x5]\n",
      "\n",
      "target:\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  1  0  0  1  0\n",
      "  1  0  0  1  0\n",
      "  1  0  1  0  1\n",
      "  1  1  0  1  1\n",
      "  1  1  0  1  1\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0  1  0  1  1\n",
      "  1  0  0  0  1\n",
      "  0  0  0  0  1\n",
      "  1  0  1  1  1\n",
      "  0  1  0  0  0\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0  1  1  1  0\n",
      "  1  0  0  1  0\n",
      "  0  0  0  0  1\n",
      "  0  0  0  1  0\n",
      "  0  1  0  0  0\n",
      "\n",
      "(3 ,.,.) = \n",
      "  1  1  1  1  1\n",
      "  0  0  1  0  1\n",
      "  1  0  0  1  1\n",
      "  0  1  1  1  0\n",
      "  0  0  1  0  1\n",
      "[torch.LongTensor of size 4x5x5]\n",
      "\n",
      "weights:\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "    1  100  100    1  100\n",
      "    1  100  100    1  100\n",
      "    1  100    1  100    1\n",
      "    1    1  100    1    1\n",
      "    1    1  100    1    1\n",
      "\n",
      "(1 ,.,.) = \n",
      "  100    1  100    1    1\n",
      "    1  100  100  100    1\n",
      "  100  100  100  100    1\n",
      "    1  100    1    1    1\n",
      "  100    1  100  100  100\n",
      "\n",
      "(2 ,.,.) = \n",
      "  100    1    1    1  100\n",
      "    1  100  100    1  100\n",
      "  100  100  100  100    1\n",
      "  100  100  100    1  100\n",
      "  100    1  100  100  100\n",
      "\n",
      "(3 ,.,.) = \n",
      "    1    1    1    1    1\n",
      "  100  100    1  100    1\n",
      "    1  100  100    1    1\n",
      "  100    1    1    1  100\n",
      "  100  100    1  100    1\n",
      "[torch.FloatTensor of size 4x5x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set properties\n",
    "batch_size = 4\n",
    "out_channels = 2\n",
    "W = 5\n",
    "H = 5\n",
    "\n",
    "# Initialize logits etc. with random\n",
    "logits = torch.FloatTensor(batch_size, out_channels, H, W).normal_()\n",
    "target = torch.LongTensor(batch_size, H, W).random_(0, out_channels)\n",
    "weights = torch.FloatTensor(batch_size, 1, H, W).random_(1, 3)\n",
    "weights = Variable(weights)\n",
    "\n",
    "\n",
    "logits = Variable(logits)\n",
    "target = Variable(target)\n",
    "\n",
    "\n",
    "weights_ = np.copy(target.data)\n",
    "ones = np.where(target.data == 1)\n",
    "weights_[weights_ == 0] = 100\n",
    "print weights_\n",
    "weights_ = Variable(torch.from_numpy(weights_).float())\n",
    "weights = weights_\n",
    "\n",
    "print \"output:\"\n",
    "print logits\n",
    "print \"target:\"\n",
    "print target\n",
    "print \"weights:\"\n",
    "print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankit/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      " -0.4645 -1.2248 -4.0145 -1.8125 -0.4151\n",
      " -0.3815 -2.3653 -1.5403 -1.2274 -0.7829\n",
      " -0.5548 -0.2226 -0.1176 -0.2221 -1.2491\n",
      " -2.6507 -1.0700 -0.5121 -0.5139 -0.9055\n",
      " -1.4578 -0.9653 -1.8254 -1.4320 -2.5783\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      " -0.9901 -0.3479 -0.0182 -0.1782 -1.0797\n",
      " -1.1483 -0.0986 -0.2412 -0.3468 -0.6108\n",
      " -0.8538 -1.6117 -2.1988 -1.6136 -0.3380\n",
      " -0.0732 -0.4201 -0.9143 -0.9116 -0.5181\n",
      " -0.2649 -0.4794 -0.1757 -0.2729 -0.0789\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -0.3466 -1.0165 -0.2699 -0.3425 -1.0661\n",
      " -1.0147 -0.6332 -0.9066 -0.5668 -0.5332\n",
      " -0.3725 -0.8596 -0.1556 -0.4147 -1.6547\n",
      " -1.5325 -1.9218 -1.4647 -0.8160 -0.7134\n",
      " -0.1308 -1.7570 -1.9421 -0.1234 -2.5091\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      " -1.2280 -0.4492 -1.4415 -1.2378 -0.4221\n",
      " -0.4502 -0.7570 -0.5173 -0.8377 -0.8837\n",
      " -1.1679 -0.5505 -1.9372 -1.0804 -0.2121\n",
      " -0.2433 -0.1582 -0.2629 -0.5838 -0.6733\n",
      " -2.0990 -0.1894 -0.1548 -2.1531 -0.0848\n",
      "[torch.FloatTensor of size 2x2x5x5]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      " -0.4645 -0.3479 -0.0182 -1.8125 -0.4151\n",
      " -1.1483 -0.0986 -1.5403 -0.3468 -0.7829\n",
      " -0.5548 -0.2226 -2.1988 -1.6136 -1.2491\n",
      " -0.0732 -1.0700 -0.9143 -0.9116 -0.9055\n",
      " -1.4578 -0.4794 -0.1757 -0.2729 -2.5783\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -1.2280 -0.4492 -1.4415 -0.3425 -0.4221\n",
      " -1.0147 -0.6332 -0.5173 -0.8377 -0.5332\n",
      " -1.1679 -0.5505 -1.9372 -0.4147 -1.6547\n",
      " -0.2433 -0.1582 -0.2629 -0.5838 -0.7134\n",
      " -2.0990 -1.7570 -0.1548 -2.1531 -0.0848\n",
      "[torch.FloatTensor of size 2x1x5x5]\n",
      "\n",
      "weighted logp\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      "  -0.0000  -34.7896   -1.8217   -0.0000   -0.0000 -114.8284   -9.8626   -0.0000\n",
      "  -0.0000  -44.9223 -144.1545   -0.0000   -0.0000 -101.4745  -63.3152   -0.0000\n",
      "\n",
      "Columns 8 to 15 \n",
      " -34.6812   -0.0000   -0.0000   -0.0000 -219.8787 -161.3640   -0.0000   -7.3216\n",
      " -83.7733   -0.0000   -0.0000   -0.0000 -193.7185  -41.4687   -0.0000  -24.3347\n",
      "\n",
      "Columns 16 to 23 \n",
      "  -0.0000  -91.4348  -91.1637   -0.0000   -0.0000  -47.9430  -17.5723  -27.2903\n",
      "  -0.0000  -26.2867  -58.3777   -0.0000   -0.0000 -175.6975  -15.4788 -215.3077\n",
      "\n",
      "Columns 24 to 31 \n",
      "  -0.0000  -46.4456  -34.7896   -1.8217   -0.0000  -41.5052   -0.0000   -0.0000\n",
      "  -0.0000 -122.7998  -44.9223 -144.1545   -0.0000  -42.2121   -0.0000   -0.0000\n",
      "\n",
      "Columns 32 to 39 \n",
      "-154.0319  -34.6812   -0.0000  -55.4785  -22.2582 -219.8787   -0.0000   -0.0000\n",
      " -51.7329  -83.7733   -0.0000 -116.7899  -55.0521 -193.7185   -0.0000   -0.0000\n",
      "\n",
      "Columns 40 to 47 \n",
      "  -7.3216 -106.9968  -91.4348  -91.1637   -0.0000 -145.7846   -0.0000  -17.5723\n",
      " -24.3347  -15.8226  -26.2867  -58.3777   -0.0000 -209.8964   -0.0000  -15.4788\n",
      "\n",
      "Columns 48 to 49 \n",
      " -27.2903 -257.8275\n",
      "-215.3077   -8.4840\n",
      "[torch.FloatTensor of size 2x50]\n",
      "\n",
      "Variable containing:\n",
      "-1.7048\n",
      "-1.5397\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "Variable containing:\n",
      " 1.6222\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate log probabilities\n",
    "logp = F.log_softmax(logits)\n",
    "\n",
    "print logp\n",
    "\n",
    "# Gather log probabilities with respect to target\n",
    "logp = logp.gather(1, target.view(batch_size, 1, H, W))\n",
    "\n",
    "print logp\n",
    "\n",
    "# Multiply with weights\n",
    "weighted_logp = (logp * weights).view(batch_size, -1)\n",
    "\n",
    "print \"weighted logp\"\n",
    "print weighted_logp\n",
    "\n",
    "# Rescale so that loss is in approx. same interval\n",
    "weighted_loss = weighted_logp.sum(1) / weights.view(batch_size, -1).sum(1)\n",
    "print weighted_loss\n",
    "\n",
    "# Average over mini-batch\n",
    "weighted_loss = -1*weighted_loss.mean()\n",
    "print weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.4645  0.3479  0.0182  1.8125  0.4151\n",
      "  1.1483  0.0986  1.5403  0.3468  0.7829\n",
      "  0.5548  0.2226  2.1988  1.6136  1.2491\n",
      "  0.0732  1.0700  0.9143  0.9116  0.9055\n",
      "  1.4578  0.4794  0.1757  0.2729  2.5783\n",
      "\n",
      "(1 ,.,.) = \n",
      "  1.2280  0.4492  1.4415  0.3425  0.4221\n",
      "  1.0147  0.6332  0.5173  0.8377  0.5332\n",
      "  1.1679  0.5505  1.9372  0.4147  1.6547\n",
      "  0.2433  0.1582  0.2629  0.5838  0.7134\n",
      "  2.0990  1.7570  0.1548  2.1531  0.0848\n",
      "[torch.FloatTensor of size 2x5x5]\n",
      "\n",
      "Variable containing:\n",
      " 45.7819\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankit/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "loss = nn.NLLLoss2d(reduce=False)\n",
    "# x has size (N, C, 224, 224)\n",
    "\n",
    "out = loss(F.log_softmax(logits), target)\n",
    "# out has size (N, 224, 224). Your weights have size (224, 224)\n",
    "\n",
    "print out\n",
    "\n",
    "result = (out * weights).mean()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  1.0895  1.8558  0.8181  0.2752  0.5931\n",
      "  0.3725  2.4772  0.5734  1.1691  0.8321\n",
      "  0.5659  0.0878  2.3359  0.0650  1.4759\n",
      "  1.5298  1.1564  3.6162  0.3829  1.3096\n",
      "  3.3427  0.1079  0.1341  1.3821  0.6473\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.9523  0.3611  0.1833  0.4688  0.2722\n",
      "  0.3201  0.2933  2.0390  0.2579  0.6597\n",
      "  0.6218  0.7128  0.0910  1.0675  3.0813\n",
      "  1.6858  0.3251  1.8899  0.5903  1.9864\n",
      "  1.7440  1.4672  0.8105  4.1898  0.6760\n",
      "\n",
      "(2 ,.,.) = \n",
      "  1.7038  0.9526  1.3221  1.2071  0.4583\n",
      "  1.8038  0.4179  0.2411  1.0174  0.8622\n",
      "  1.3168  1.3444  1.8728  0.8415  0.9007\n",
      "  0.2371  2.0529  0.0816  1.3199  1.2632\n",
      "  1.9825  0.0670  1.3228  1.1100  0.3586\n",
      "\n",
      "(3 ,.,.) = \n",
      "  0.3439  2.3560  1.6835  0.2225  1.0442\n",
      "  0.7786  1.5563  0.5272  1.9944  0.5128\n",
      "  0.0576  1.3773  0.5473  0.7360  2.3415\n",
      "  1.0064  0.2583  1.5707  0.5667  0.0954\n",
      "  1.7030  0.3376  0.8128  0.0453  0.2131\n",
      "[torch.FloatTensor of size 4x5x5]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "    1.0895  185.5765   81.8112    0.2752   59.3114\n",
      "    0.3725  247.7169   57.3421    1.1691   83.2063\n",
      "    0.5659    8.7831    2.3359    6.5007    1.4759\n",
      "    1.5298    1.1564  361.6195    0.3829    1.3096\n",
      "    3.3427    0.1079   13.4147    1.3821    0.6473\n",
      "\n",
      "(1 ,.,.) = \n",
      "   95.2259    0.3611   18.3290    0.4688    0.2722\n",
      "    0.3201   29.3318  203.8950   25.7940    0.6597\n",
      "   62.1818   71.2810    9.0961  106.7511    3.0813\n",
      "    1.6858   32.5127    1.8899    0.5903    1.9864\n",
      "  174.3960    1.4672   81.0452  418.9768   67.5984\n",
      "\n",
      "(2 ,.,.) = \n",
      "  170.3846    0.9526    1.3221    1.2071   45.8270\n",
      "    1.8038   41.7883   24.1124    1.0174   86.2159\n",
      "  131.6822  134.4395  187.2812   84.1534    0.9007\n",
      "   23.7102  205.2948    8.1622    1.3199  126.3210\n",
      "  198.2525    0.0670  132.2844  111.0009   35.8606\n",
      "\n",
      "(3 ,.,.) = \n",
      "    0.3439    2.3560    1.6835    0.2225    1.0442\n",
      "   77.8615  155.6346    0.5272  199.4354    0.5128\n",
      "    0.0576  137.7283   54.7338    0.7360    2.3415\n",
      "  100.6406    0.2583    1.5707    0.5667    9.5399\n",
      "  170.3049   33.7596    0.8128    4.5268    0.2131\n",
      "[torch.FloatTensor of size 4x5x5]\n",
      "\n",
      "Variable containing:\n",
      " 52.4440\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss(reduce=False)\n",
    "# x has size (N, C, 224, 224)\n",
    "\n",
    "out = loss(logits, target)\n",
    "# out has size (N, 224, 224). Your weights have size (224, 224)\n",
    "\n",
    "print out\n",
    "\n",
    "result = (out * weights)\n",
    "print result\n",
    "result = result.mean()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 100.  100.  100.  100.  100.]\n",
      "  [ 100.  100.  100.  100.  100.]\n",
      "  [ 100.  100.  100.  100.  100.]\n",
      "  [ 100.  100.  100.  100.  100.]\n",
      "  [ 100.  100.  100.  100.  100.]]\n",
      "\n",
      " [[ 100.  100.  100.  100.  100.]\n",
      "  [ 100.  100.  100.  100.  100.]\n",
      "  [ 100.  100.  100.  100.  100.]\n",
      "  [ 100.  100.  100.  100.  100.]\n",
      "  [ 100.  100.  100.  100.  100.]]]\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.8667  0.7961  0.3411  1.2604  0.2871\n",
      "  0.1586  0.6139  1.9757  1.7881  1.1660\n",
      "  0.8096  0.1247  0.6719  1.1646  2.0752\n",
      "  0.0268  0.4686  0.7808  0.9574  0.8307\n",
      "  0.0618  0.4963  1.2791  1.5468  0.0587\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.3329  0.5207  0.3794  0.2378  1.0390\n",
      "  0.4733  0.1951  1.2841  1.8604  2.3195\n",
      "  0.4336  1.6380  2.4496  0.2968  0.0990\n",
      "  1.2509  0.5078  0.8905  0.5509  0.3856\n",
      "  1.1532  1.7875  0.2760  0.0482  0.0495\n",
      "[torch.FloatTensor of size 2x5x5]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "   86.6683   79.6118   34.1091  126.0409   28.7071\n",
      "   15.8585   61.3879  197.5660  178.8054  116.5978\n",
      "   80.9576   12.4655   67.1896  116.4551  207.5230\n",
      "    2.6775   46.8631   78.0768   95.7406   83.0675\n",
      "    6.1780   49.6338  127.9075  154.6798    5.8732\n",
      "\n",
      "(1 ,.,.) = \n",
      "   33.2938   52.0713   37.9426   23.7754  103.9034\n",
      "   47.3321   19.5118  128.4105  186.0366  231.9507\n",
      "   43.3640  163.7976  244.9560   29.6760    9.8961\n",
      "  125.0940   50.7830   89.0500   55.0936   38.5566\n",
      "  115.3186  178.7540   27.5961    4.8245    4.9476\n",
      "[torch.FloatTensor of size 2x5x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights_ = np.zeros(target.size())\n",
    "\n",
    "ones = np.where(target.data == 1)\n",
    "\n",
    "weights_[target.data == 0] = 100\n",
    "\n",
    "print weights_\n",
    "\n",
    "\n",
    "weights_ = Variable(torch.from_numpy(weights_).float())\n",
    "print out\n",
    "print out*weights_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
